```{r setup, include=FALSE}
legaldmlab::primeR(analysis_type = "Bayes")
```

# Part 4: Examining the Posterior

The following two commands are your best options for examining posterior effects:

```{r}
brms::fixef(b5.3) # uses quantile-based intervals only

bayestestR::describe_posterior(b5.3, ci_method = "HDI", ci = .95) # most detailed info, and can change to HDI
```

-   Do note though that the table that is printed in the console/in RMarkdown when you use `describe_posterior` is cleaned up and formatted...if you save this table in the environment, it will be a regular data frame with un-rounded columns, etc. If you want to save the table exactly how it is printed in the console (i.e., rounded to two decimals, ROPE and CI columns combined in APA style, etc.), to export an APA formatted table, pipe `describe_posterior` to `insight::format_table()`.

## Effect Existence and Significance

[Makowski et al. (2019)](https://www.frontiersin.org/articles/10.3389/fpsyg.2019.02767/full) recommends the following:

-   At least one index of effect *existence* (preferably the **Probability of direction**)
-   At least one index of effect *significance* (either the **ROPE test or a Bayes factor**, depending on the situation)
    -   If you have little prior information to go off of in your study and thus have used *weak priors* and are *unsure what to expect* regarding the effect size, [you should report the ROPE test]{.underline}*.*

    -   If you used more informative priors and have a more clear idea of the expected effect size, [use Bayes factors.]{.underline}

```{r}

describe_posterior(fit, 
                   ci_method = "HDI", ci=.89, 
                   rope_range = c(-.25, .25), rope_ci = .95)


rope_test=bayestestR::rope(fit, rope_range = c(-.25, .25)) |> 
  mutate(result=interpret_rope(ROPE_Percentage)) |> 
  as_tibble() |> 
  select(-c(Component, Effects))

rope_test


# ROPE and HDI plot
plot(rope_test, rope_color = "grey70") +
  theme(panel.grid = element_blank())

# probability of direction plot
plot(pd(fit)) + scale_fill_brewer(type = "qual")

# plot of coefficient estimates
mcmc_plot(fit, pars = "^b_")
```

### Effect Existence

The most basic inferential statistic, it is the maximal probability the our estimate is strictly directional; that is, larger or smaller than 0, and it generally ranges from 50% (no preference) to 100%.

Moreover, it is strongly correlated with the frequentest p-value, and can thus be used to draw parallels and give some reference to readers non-familiar with Bayesian statistics. A two-sided p-value of respectively .1, .05, .01 and .001 would correspond approximately to a pd of 95%, 97.5%, 99.5% and 99.95%. Thus, for convenience, we suggest the following reference values as an interpretation helpers:

```         
pd <= 95% ~ p > .1: uncertain
pd > 95% ~ p < .1: possibly existing
pd > 97%: likely existing
pd > 99%: probably existing
pd > 99.9%: certainly existing
```

### Effect Magnitude

`rope()` computes the portion of the HDI (defualt to 89% of HDI) of a posterior distribution that lies within a Region of Practical Equivilence (ROPE).

*This is used instead of a Null Hypothesis test because statistically, testing that the probability of a posterior distribution being different from 0 does not make sense (i.e., the probability of being different from any single point is infinite). The purpose therefore of using a ROPE test is to let the user define an area around the null value enclosing values that would be equivalent to the null, for practical purposes.*

You can do a ROPE test two different ways:

1.  Test the full posterior to see what percentage of *all possible values* fall in the null band (this is called the full ROPE), or

2.  Test against the most probable values (those within the 89% or 95% HDI).

Either method is fine (although the full ROPE is more sensitive to delineating highly-significant effects), and the results are interpreted similarly: The proportion of the HDI inside this "null" region can be used as a decision criterion for "NH" testing; that is, a test for "Practical Equivalence", or that an effect is large enough to have "practical" (as opposed to purely statistical) significance.

Also in either case, you are encouraged to interpret the results of the test in a continuous and probabilistic (i.e., not black-and-white or all-or-nothing) sense; do not use it like a Null Hypothesis test. ROPE is an index that tells you whether a parameter is related - or not - to a non-negligible change (in terms of magnitude) in the outcome. However, based on simulation data, we suggest the following reference values as an interpretation helpers:

```         
> 99% in ROPE: negligible (we can accept the null hypothesis)

> 97.5% in ROPE: probably negligible

<= 97.5% & >= 2.5% in ROPE: undecided significance

< 2.5% in ROPE: probably significant

< 1% in ROPE: significant (we can reject the null hypothesis)
```

**Note that extra caution is required as its interpretation highly depends on other parameters such as sample size and ROPE range**. See [this link](https://easystats.github.io/bayestestR/articles/region_of_practical_equivalence.html#sensitivity-to-parameters-scale).
