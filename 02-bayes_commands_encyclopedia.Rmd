---
title: "Untitled"
output: html_document
date: '2022-07-15'
---

Some preliminary set up...Lets build two simple models to run all the following code on

```{r setup, include=FALSE}

pacman::p_load(tidyverse, bayesplot, tidybayes, brms, easystats)

# ========================= LINEAR ===============================================
data(WaffleDivorce, package = "rethinking")
d <- WaffleDivorce

d <-
  d %>% 
  mutate(d = rethinking::standardize(Divorce),
         m = rethinking::standardize(Marriage),
         a = rethinking::standardize(MedianAgeMarriage))

b5.3 <- 
  brm(data = d, 
      family = gaussian,
      d ~ 1 + m + a,
      prior = c(prior(normal(0, 0.2), class = Intercept),
                prior(normal(0, 0.5), class = b),
                prior(exponential(1), class = sigma)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 5)


# ========================= LOGISTIC ===============================================

my_data=read.csv("C:/Users/rschn/OneDrive/R Sandbox/Data Repository/Kruschke data/HtWtData110.csv")

my_data <-
  my_data %>% 
  mutate(height_z = (height - mean(height)) / sd(height),
         weight_z = (weight - mean(weight)) / sd(weight))

logistic_fit <-
  brm(data = my_data, 
      family = bernoulli,
      male ~ 1 + weight_z + height_z,
      prior = c(prior(normal(0, 2), class = Intercept),
                prior(normal(0, 2), class = b)),
      iter = 2500, warmup = 500, chains = 4, cores = 4,
      seed = 21)
```

## I. BRMS SETTINGS

Common stuff you should know...

### `iter`, `chains`, and `warmup`

-   `iter` is the number of steps taken in each chain. Kurz in chapter 4 notes: "you usually only need to set `iter= 2000, warmup=1000` when using moderately better priors [than these terrible uniform ones]." You usually don't need more than a few thousand steps per chain, if you have a relatively simple model and you're only trying to get estimates of the parameters.

-   `warmup` is how many of the steps specified in `iter` will be used for a "warm-up" run and discarded.

-   You don't need more than 3-4 chains for most models.

### `seed`

x

### Variable coding and the intercept

-   *You do not have to do anything special to dummy-code a model, just leave it as is. If you do not include the* `1` *in the formula, it's there invisible by default*

-   If you want to index code, you need to manually surpress the intercept by switching the `1` to `0`. If you have multiple variables, you need to use the last version that includes the command `nl=TRUE`

-   In either case, store your factors as `as.factor` to make things simple (but I don't think this matters)

```{r eval=FALSE}
brms_dummy <-brm(formula = plea_sentence_months ~ 1 + poc,
                   family = gaussian(link = "identity"),
                   data = practice_data,
                   prior = c(prior(normal(108, 24), class = Intercept),
                             prior(lognormal(0, 5), class = sigma), 
                             prior(normal(0, 10), class = b)), 
                   iter = 3000, warmup = 750, chains = 4, cores = 4)


brms_index <-brm(formula = plea_sentence_months ~ 0 + poc,
                   family = gaussian(link = "identity"),
                   data = practice_data,
                   prior = c(prior(lognormal(0, 5), class = sigma), 
                             prior(normal(50, 24), class = b, coef=poc0.2),
                             prior(normal(108, 24), class = b, coef=poc0.5),
                             prior(normal(173, 24), class = b, coef=poc0.8)),
                   iter = 3000, warmup = 750, chains = 4, cores = 4)


brms_index_2 <-brm(data = d,
                   family = gaussian,
                   bf(kcal.per.g_s ~ 0 + a + h, 
                      a ~ 0 + clade, 
                      h ~ 0 + house, 
                      nl = TRUE), # this line is the fix
                   prior = c(prior(normal(0, 0.5), nlpar = a),
                             prior(normal(0, 0.5), nlpar = h),
                             prior(exponential(1), class = sigma)),
                   iter = 2000, warmup = 1000, chains = 4, cores = 4,
                   seed = 5,
                   file = here::here("fits", "b05.11"))
```

An Index variable is one variable that has one level for each category of the factor. A dummy (AKA "Indicator") variable is k-1 variables that are coded 0/1 to indicate the presence or absence of a level.

The difference between two groups is another parameter that you have to estimate; *you cannot assume that the difference between two groups, as it is observed in your sample, is measured perfectly without any error.* The distance between the center of two distributions requires an estimate.

Dummy and index models are doing very similar things, just from different angles. The dummy-coded model calculates an intercept (i.e., the average starting value) across the whole sample, and then compares the difference from each group to the intercept. In this case, the estimated beta-weights represent the changes/slopes/correlation coefficients.

Index models instead calculate a separate intercept (i.e., the mean) for each level/group on its own. In this instance, the beta's represent the means of each group. This let's you compute the differences between two groups easier than the dummy-model.

## II. Updating or fitting additional models

Do you want to fit more than one model on the same data? Of course you do. If the models aren't radically different, it might be easier to use the `update` function that fitting each model anew with another `brm()` call. Using `update()` lets brms reuse the stan code it compiled for the first model, so it takes less time to build subsequent models.

Also it saves lines of code and reduces chances of copy/paste-born errors.

```{r}
# fit initial model
brms_index <-brm(formula = plea_sentence_months ~ 0 + poc,
                   family = gaussian(link = "identity"),
                   data = practice_data,
                   prior = c(prior(normal(0, 3), class = sigma), 
                             prior(normal(0, 3), class = b, coef=poc0.)),
                   iter = 20000, warmup = 8000, chains = 4, cores = 4, seed = 4)

# create a new model by updating the initial one, by adding the intercept parameter back in
brms_dummy_single <-update(brms_index, newdata = practice_data,
                           formula. = ~ .+1,
                           prior = c(prior(normal(3, 2), class = Intercept)))

# update again to create a third model with more predictors
brms_dummy_multi <-update(brms_dummy_single, newdata = practice_data,
                          formula. = ~ .-poc + poc_5 + poc_8)
```

## III. SUMMARIZING EFFECTS

These two upper commands give summaries of ALL effects, including the sigma parameter and the Log Posterior Density (lp\_\_). The two lower ones are probably what you'll want to use. They give you info on *only the main effects*. No sigma, and no lp\_\_.

```{r}
brms::posterior_summary(b5.3)

parameters::model_parameters(b5.3)

# ====================================================================================

brms::fixef(b5.3)

bayestestR::describe_posterior(b5.3) # most detailed info on the posterior main effects
```

-   Do note though that the table that is printed in the console/in RMarkdown when you use `describe_posterior` is cleaned up and formatted...if you save this table in the environment, it will be a regular data frame with un-rounded columns, etc.

-   If you want to save the table exactly how it is printed in the console (i.e., rounded to two decimals, ROPE and CI columns combined in APA style, etc.), to export an APA formatted table, pipe `describe_posterior` to `insight::format_table()`.

```{r}
describe_posterior(b5.3) |> format_table()
```

## IV. EXTRACTING \_\_\_ FROM THE\_\_\_

### ...draws from the posterior

-   These commands draw samples of *parameter values* from the posterior.

-   Kurz uses `brms::posterior_samples` in his translation books but this is DEPRICATED. Best bet is to use `tidy_draws`; see [here](SEE%20https://mjskay.github.io/tidybayes/articles/tidy-brms.html#introduction) for info. The {tidybayes} package follows the tidyverse format.

```{r}
insight::get_parameters(b4.3) |> head() # comparable to posterior_samples, except it doesn't give you samples for lp__

tidybayes::tidy_draws(b4.3) |> head() # USE THIS ONE. {tidybayes} is useful for extracting draws in a form and manner consistent w/ the tidyverse.
```

### ...draws from the PRIOR Predictive Distribution

-   When performing prior predictive checks (below), the following command can be used to extract values from the prior to show what the model expects, *before* seeing the observed data.

```{r}
brms::prior_draws()
```

### ...fitted (i.e., predicted) values from the POSTERIOR Predictive Distribution

-   This is a method that uses the posterior to generate data that would be expected by the model. The results of these commands return *the data your model would expect to see,* given the parameters implied in the posterior.

> With `fitted()`, we compute the expected values for each state.

```{r}
fitted(b5.4) |> as_tibble() |> head()
```

Kurz extracts the fitted values (values expected by the model) and then binds this back in with the full data

```{r}
fitted(b5.4) |> data.frame() |> bind_cols(d) |> head()
```

### ...residuals from the model

Same as above, but switch `fitted()` for `residuals()`

```{r}

residuals(b5.4b) |> 
  data.frame() |> 
  bind_cols(d)
```

## V. MONTE CARLO DIAGNOSTICS

### Qualitative diagnostics

{bayesplot} is good for diagnostic plots: <https://mc-stan.org/bayesplot/>

```{r}

```

### Quantitative diagnostics (ESS and Rhat)

Estimated Sample Size (ESS) and Rhat are two MCMC diagnostic indicators for MCMC/HMC models invented and used by Vehtari, Gelman, and the like. Good indicators to check, and easy to do so with the easystats suite.

-   Rhat should be \>1000

-   ESS should be...

```{r}
 # extract info from model
diag=bayestestR::diagnostic_posterior(b5.3)

# check Rhat
diag$Rhat |> effectsize::interpret_rhat()

# check ESS
diag$ESS |> effectsize::interpret_ess()
```

## VI. BAYESIAN PLOTS AND FIGURES

### Bayes factors, ROPE's, posteriors, etc.

<https://easystats.github.io/see/articles/bayestestR.html>

-   The {see} and {bayestestR} packages making plotting Bayesian models very easy. General format for almost everything is the same...

-   To plot just the thing, combine the desired {bayestestR} command with `plot`; for example:

```{r}
plot(bayestestR::rope(b5.3))
```

To customize the look and appearance of the plot, use the same format as above, and add ggplot themes or themes and colors from other packages:

```{r}
plot(bayestestR::hdi(b5.3)) + 
  theme_classic()+
  scale_fill_metro(palette = "ice")

plot(bayestestR::pd(b5.3)) + 
  theme_classic()+
  scale_fill_metro(palette = "ice")
```

### Coefficient estimates

See this page for help: <https://cran.r-project.org/web/packages/bayesplot/vignettes/plotting-mcmc-draws.html>

```{r}
# Simple quick-and-dirty option
mcmc_plot(b5.9, pars = "^b_")


# fancy version

library(bayesplot)

color_scheme_set("red")

post <- tidybayes::tidy_draws(b5.9)

post %>% 
  select(starts_with("b_")) %>% 
  
  bayesplot::mcmc_intervals(prob = .5, point_est = "median") + # the key plotting feature here
  
  labs(title = "My fancy coefficient plot") +
  theme_bw() +
  theme(axis.text.y = element_text(hjust = 0),
        axis.ticks.y = element_blank(),
        panel.grid = element_blank())
```

## VII. PREDICTIVE CHECKS FOR BRMS MODELS

Both prior and posterior predictive checks below.

### A. PRIOR predictive checks

When building the model, set `sample_prior=TRUE`

```{r}
b5.1 <- 
  brm(data = d, 
      family = gaussian,
      d ~ 1 + a,
      prior = c(prior(normal(0, 0.2), class = Intercept),
                prior(normal(0, 0.5), class = b),
                prior(exponential(1), class = sigma)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 5,
      sample_prior = T,
      file = "../fits/b05.01")
```

Then extract draws from the prior using the command noted above and plot

```{r}
some_draws=brms::prior_draws(b5.1)

some_draws %>% 
  slice_sample(n = 50) %>% 
  rownames_to_column("draw") %>% 
  expand(nesting(draw, Intercept, b),
         a = c(-2, 2)) %>% 
  mutate(d = Intercept + b * a) %>% 
  
  ggplot(aes(x = a, y = d)) +
  geom_line(aes(group = draw),
            color = "firebrick", alpha = .4) +
  labs(x = "Median age marriage (std)",
       y = "Divorce rate (std)") +
  coord_cartesian(ylim = c(-2, 2)) +
  theme_bw() +
  theme(panel.grid = element_blank())

```

### B. POSTERIOR Predictive Checks

#### ...for linear models

First extract the values predicted by the model with `fitted()`, as noted above; then combine this with the data and pipe to ggplot

```{r}
brms_fit <-brm(price ~ 1 + carat,
               family = gaussian(link = "identity"),
               data = diamonds,                
               prior = c(
                 prior(normal(3, 2), class = Intercept),
                 prior(normal(0, 3), class= sigma), 
                 prior(normal(0, 3), class = b)), 
               iter = 28000, warmup = 27000, chains = 3, cores = 3, seed = 4)


fitted(brms_fit) %>% # extract fitted predictions
  data.frame() %>% # convert from matrix to df
  bind_cols(diamonds) %>% # combine this with the original data
  #...and pass to ggplot
  
  ggplot(aes(x = price, y = Estimate)) + # change x-axis to DV name!
  geom_abline(linetype = 2, color = "grey50", size = .5) +
  geom_point(size = 1.5, color = "firebrick4", alpha = 3/4) +
  geom_linerange(aes(ymin = Q2.5, ymax = Q97.5),
                 size = 1/4, color = "firebrick4") +
  #geom_text(data = . %>% filter(Loc %in% c("ID", "UT", "RI", "ME")),
  #         aes(label = Loc), hjust = 1, nudge_x = - 0.25) +
  labs(x = "Observed", y = "Predicted") +
  theme_bw() +
  theme(panel.grid = element_blank())
```

This shows a regression line. To plot and compare the predicted posterior densities, use either of the following:

```{r}
performance::posterior_predictive_check(brms_fit)
pp_check(brms_fit)
```

Note that these two commands are basically identical. This is because the former merely acts as a easy-to-remember shortcut that passes your model to the latter.

There is a third command called `ppc_dens_overlay` but I'm not clear on what that does and when to use it.

#### ...for logistic models

## VIII. COMPUTING PERFORMANCE INDICIES

You can do this at least two different ways. There's the way Kurz does it:

```{r}

# compute estimates of LOO and WAIC and add directly to the model object
b5.1 <- add_criterion(b5.1, criterion = c("loo", "waic"))
b5.2 <- add_criterion(b5.2, criterion = c("loo", "waic"))
b5.3 <- add_criterion(b5.3, criterion = c("loo", "waic"))

# compare the estimates
loo_compare(b5.1, b5.2, b5.3, criterion = "loo") |>  
  print(simplify = F)

loo_compare(b5.1, b5.2, b5.3, criterion = "waic") |>  
  print(simplify = F)
```

Or, the much faster and more efficient way using the easystats package:

```{r}
compare_performance(b6.6, b6.7, b6.8, metrics=c("WAIC", "LOOIC"), rank = FALSE) |> select(-Model)
```
